{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "# pd.set_option('display.max_rows', 8)\n",
    "!date\n",
    "!whoami\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlns_summarizer as sqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell for editing input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory for output files. Subdirectories are assumed to be of the form 'location/run_date/'\n",
    "base_directory = '/share/costeffectiveness/results/sqlns/presentation/'\n",
    "\n",
    "# Map countries to the correct run date = subdirectory name\n",
    "locations_run_dates = {\n",
    "#     'Bangladesh': '2019_07_02_11_55_19',\n",
    "#     'Burkina_Faso': '2019_07_02_11_56_40',\n",
    "#     'Ethiopia': '2019_07_02_11_58_02',\n",
    "#     'India': '2019_07_02_11_58_29',\n",
    "    'Nigeria': '2019_07_23_10_57_25', #'2019_07_18_13_20_17',\n",
    "    }\n",
    "\n",
    "locations = list(locations_run_dates.keys())\n",
    "    \n",
    "intervention_colname_mapper = {\n",
    "        'sqlns.effect_on_child_stunting.permanent': 'stunting_permanent',\n",
    "        'sqlns.effect_on_child_wasting.permanent': 'wasting_permanent',\n",
    "        'sqlns.effect_on_iron_deficiency.permanent': 'iron_permanent',\n",
    "        'sqlns.duration': 'duration',\n",
    "        'sqlns.effect_on_iron_deficiency.mean': 'iron_mean',\n",
    "        'sqlns.effect_on_iron_deficiency.sd': 'iron_sd', \n",
    "        'sqlns.program_coverage': 'coverage',\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Typical list of data transformations we need for data analysis\n",
    "\n",
    "**X** indicates that I have already implemented a version of the transformation, either below or in `sqlns_summarizer.py`.\n",
    "\n",
    "1. **X** Load data from different locations and concatenate into single output file with location names added\n",
    "2. **X** Verify column name categories\n",
    "3. Verify random seed, input draw, and scenario counts compared to the number of rows in the output. If random seeds are missing (which often happens), it can lead to weird looking graphs and/or errors in the data processing code (particularly if an entire draw is missing for some scenario).\n",
    "3. **Perhaps draw some simple graphs before any data processing, to verify the results as close to the raw data as possible**\n",
    "4. **X** Rename the intervention columns with shorter names\n",
    "5. **X** Sum over random seeds\n",
    "6. **X** Parse column names to extract measure, cause, risk, sequela, year, sex, age, etc.\n",
    "6. **Perhaps draw more graphs at this step, again to verify the results as close to the raw data as possible**\n",
    "7. Do any desired case-specific aggregations or additions of derived measures (e.g. in mom_food model, sum over age groups and sexes and years, and sum over all neonatal causes).\n",
    "    * Note: This step cannot be made generic, though perhaps there could be some wrapper functions for common tasks to make them easier.\n",
    "8. Stack dataframes to put them in a form more convenient for analysis. Replace `NaN`s with 'all' where appropriate (e.g. for person time or total dalys). I think we want to stack before dividing or subtracting in order to make broadcasting easier.\n",
    "9. For deaths, ylls, ylds, dalys, compute rate per person-year (i.e. divide by person time)\n",
    "10. For risks and sequela, compute exposures/prevalences (i.e. percentages) in relevant categories. Allow specification of categories, e.g. using my `risk_mapper` module.\n",
    "10. Do something with the 'diseases_at_end', 'disease_event_count', and 'population' columns if desired.\n",
    "11. Subtract dataframes to compute averted/delta measures\n",
    "12. **Draw some more graphs at this point to verify results at the draw level before aggregating**\n",
    "12. Aggregate over draws to compute mean, upper and lower percentiles\n",
    "13. Concatenate stacked dataframes to get final output\n",
    "14. **Draw final graphs displaying desired results**\n",
    "\n",
    "## Functions to perform data transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_by_location_and_rundate(base_directory: str, locations_run_dates: dict) -> pd.DataFrame:\n",
    "    \"\"\"Load output.hdf files from folders namedd with the convention 'base_directory/location/rundate/output.hdf'\"\"\"\n",
    "    \n",
    "    # Use dictionary to map countries to the correct path for the Vivarium output to process\n",
    "    # E.g. /share/costeffectiveness/results/sqlns/bangladesh/2019_06_21_00_09_53\n",
    "    locactions_paths = {location: f'{base_directory}/{location.lower()}/{run_date}/output.hdf'\n",
    "                       for location, run_date in locations_run_dates.items()}\n",
    "\n",
    "    # Read in data from different countries\n",
    "    locations_outputs = {location: pd.read_hdf(path) for location, path in locactions_paths.items()}\n",
    "\n",
    "    for location, output in locations_outputs.items():\n",
    "        output['location'] = location\n",
    "    \n",
    "    return pd.concat(locations_outputs.values(), copy=False, sort=False)\n",
    "    \n",
    "def print_location_output_shapes(locations, all_output):\n",
    "    \"\"\"Print the shapes of outputs for each location to check whether all the same size or if some data is missing\"\"\"\n",
    "    for location in locations:\n",
    "        print(location, all_output.loc[all_output.location==location].shape)\n",
    "        \n",
    "def negate_column(output, column_name):\n",
    "    \"\"\"Negate a column of the dataframe ('sqlns_treated_days')\"\"\"\n",
    "    output[column_name] = -1 * output[column_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_and_reindex_subdataframes(output, intervention_colname_mapper):\n",
    "    \"\"\"\n",
    "    Performs 3 of the transfrmations listed above:\n",
    "    - Rename intervention columns with shorter names\n",
    "    - Sum over random seeds\n",
    "    - Parse column names to extract measure, cause, risk, sequela, year, sex, age, etc.,\n",
    "      and use these to reindex the categorized subdataframes with MultiIndices\n",
    "    \"\"\"\n",
    "    output.rename_intervention_columns(intervention_colname_mapper)\n",
    "    output.sum_over_random_seeds()\n",
    "    output.parse_column_names_and_reindex()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and check shape of output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_output = load_by_location_and_rundate(base_directory, locations_run_dates)\n",
    "print_location_output_shapes(locations, all_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix the negative `'sqlns_treated_days'` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oops, 'sqlns_treated_days' got subtracted in the wrong order\n",
    "# Fix by replacing column with its negation\n",
    "negate_column(all_output, 'sqlns_treated_days')\n",
    "all_output['sqlns_treated_days'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an OutputSummarizer from the data\n",
    "\n",
    "Then check the column categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = sqs.SQLNSOutputSummarizer(all_output)\n",
    "output.print_column_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output._columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.columns('diseases_at_end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.columns('disease_event_count', 'population')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output._columns[['disease_event_count', 'population']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.columns('population')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.subdata['population'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "9683+11685"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10563+1122"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pattern = re.compile('^(?:(?P<category>susceptible)_to_|(?P<category>recovered)_from_|(?P<category>))(?P<cause>\\w+)_(?P<measure>event_count)$')\n",
    "pattern = re.compile('^(?P<category>susceptible|recovered|)(?:_to_|_from_|)(?P<cause>\\w+)_(?P<measure>event_count)$')\n",
    "matches = []\n",
    "\n",
    "matches.append(pattern.search('susceptible_to_measles_event_count'))\n",
    "matches.append(pattern.search('measles_event_count'))\n",
    "matches.append(pattern.search('recovered_from_measles_event_count'))\n",
    "for match in matches:\n",
    "    print(match.groups())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile('^total_(?P<measure>population)(?:_|)(?P<category>\\w*)')\n",
    "matches = []\n",
    "matches.append(pattern.search('total_population'))\n",
    "matches.append(pattern.search('total_population_living'))\n",
    "matches.append(pattern.search('total_population_dead'))\n",
    "for match in matches:\n",
    "    print(match.groups())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename the intervention columns, sum over random seeds, parse column names, and reindex subdataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_and_reindex_subdataframes(output, intervention_colname_mapper)\n",
    "output.subdata['intervention'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.subdata['random_seed'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.data[output.columns('random_seed')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.subdata['mortality'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.subdata['categorical_risk'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.data[output.columns('categorical_risk')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.subdata['population'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment the extraction regex for 'population' to see the results of this\n",
    "# output.subdata['population'][('population','')][('Nigeria', False)].head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.columns('population')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series({0: [4,5,6], 1: [1,2], 2: [3]})\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[[0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for l in s[[0,1]] for x in l]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check output for monotonicity with coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "\n",
    "output.data.loc[idx['Nigeria', False, False, False, 365.25, 0.895, 0.0656, :, 357],\n",
    "                ['death_due_to_other_causes', 'death_due_to_diarrheal_diseases', 'ylds_due_to_iron_deficiency']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.data.loc[idx['Nigeria', False, False, False, 365.25, 0.895, 0.0656, :, 55],\n",
    "                ['years_of_life_lost', 'years_lived_with_disability', 'random_seed_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.subdata['random_seed'].iloc[:,0].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.data.loc[output.subdata['random_seed'].iloc[:,0]==3,\n",
    "                ['years_of_life_lost', 'years_lived_with_disability', 'random_seed_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "18*5*108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "9720-9683"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.column_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.subdata['mortality'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.subdata['categorical_risk'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.subdata['graded_sequela'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reindex sub-dataframes to extract cause names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the yld columns\n",
    "yld_df = all_output.filter(regex='yld')\n",
    "yld_decomp = yld_df.columns.str.extract(\n",
    "    '^(?P<measure>ylds)_due_to_(?P<cause>\\w+?)(?:_in_(?P<year>\\d{4})|)(?:_among_(?P<sex>male|female)|)(?:_in_age_group_(?P<age_group>\\w+)|)$'\n",
    ")\n",
    "yld_decomp\n",
    "# yld_df.columns = pd.MultiIndex.from_frame(yld_decomp.dropna(axis='columns', how='all'))\n",
    "# yld_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.reindex_sub_dataframes()\n",
    "output.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.subdata['mortality'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.subdata['mortality'].stack(level='measure').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.subdata['mortality'].stack(level=output.subdata['mortality'].columns.names).reset_index().head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.subdata['person_time'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.subdata['person_time'].stack(level=0).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:vivarium_conic_sqlns]",
   "language": "python",
   "name": "conda-env-vivarium_conic_sqlns-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
