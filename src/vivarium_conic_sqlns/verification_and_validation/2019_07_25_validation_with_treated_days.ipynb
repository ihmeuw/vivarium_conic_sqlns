{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Yongquan Xie, Nathaniel Blair-Stahn<br>\n",
    "Date: July 25, 2019<br>\n",
    "Purpose: SQ-LNS presentation Nigeria results preparation<br>\n",
    "Note: Yongquan and Nathaniel will give this presentation on August 1, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "\n",
    "pd.set_option('display.max_rows', 8)\n",
    "\n",
    "!date\n",
    "!whoami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load output data and aggregate over random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cause_names = ['lower_respiratory_infections', 'measles', 'diarrheal_diseases', \n",
    "               'protein_energy_malnutrition', 'iron_deficiency', 'other_causes']\n",
    "risk_names = ['anemia', 'child_stunting', 'child_wasting']\n",
    "\n",
    "template_cols = ['coverage', 'duration', 'child_stunting_permanent', \n",
    "                 'child_wasting_permanent', 'iron_deficiency_permanent', \n",
    "                 'iron_deficiency_mean', 'cause', 'measure', 'input_draw']\n",
    "\n",
    "result_dir = '/share/costeffectiveness/results/sqlns/presentation/nigeria/2019_07_23_10_57_25'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that we have applied coefficient of variation as constant with different sqlns effect on iron deficiency\n",
    "def clean_and_aggregate(path, filename):\n",
    "#     r = pd.read_hdf(path + 'nigeria/2019_07_18_13_20_17/output.hdf')\n",
    "    r = pd.read_hdf(f'{path}/{filename}')\n",
    "    r.rename(columns={'sqlns.effect_on_child_stunting.permanent': 'child_stunting_permanent',\n",
    "                      'sqlns.effect_on_child_wasting.permanent': 'child_wasting_permanent',\n",
    "                      'sqlns.effect_on_iron_deficiency.permanent': 'iron_deficiency_permanent',\n",
    "                      'sqlns.effect_on_iron_deficiency.mean': 'iron_deficiency_mean',\n",
    "                      'sqlns.program_coverage': 'coverage',\n",
    "                      'sqlns.duration': 'duration'}, inplace=True)\n",
    "    r['coverage'] *= 100\n",
    "    # The 'sqlns_treated_days' column got subtracted in the wrong order for the 2019_07_23_10_57_25 run:\n",
    "    r['sqlns_treated_days'] = -1 * r['sqlns_treated_days'] # This line should be deleted once the code is fixed\n",
    "    r = r.groupby(['coverage', 'duration', 'child_stunting_permanent', 'child_wasting_permanent', 'iron_deficiency_permanent', 'iron_deficiency_mean', 'input_draw']).sum()\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load outpt data - as of 2019-07-25 there are random seeds missing\n",
    "r = clean_and_aggregate(result_dir, 'output.hdf')\n",
    "# Raw data aggregated by random seed, with intervention columns renamed\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a list of the unique draws for plotting by draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draws = r.reset_index().input_draw.unique()\n",
    "draws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot total YLLs and YLDs vs. coverage for each draw\n",
    "\n",
    "Raw YLLs and YLDs are plotted side by side with the rates per 100,000 person years. Plots should be monotonically decreasing as coverage level increases.\n",
    "\n",
    "Create a `pandas.IndexSlice` object to easily select with the multi-index of the original aggregated dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas IndexSlice object to easily multi-index the original dataframe\n",
    "idx = pd.IndexSlice\n",
    "r.loc[idx[:, 365.25, False, False, False, 0.895, 55],\n",
    "      ['years_of_life_lost', 'years_lived_with_disability', 'person_time']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact()\n",
    "def plot_total_dalys_by_draw(duration=[365.25, 730.50],\n",
    "                    cgf_permanent=[False, True],\n",
    "                    iron_permanent=[False, True],\n",
    "                    iron_mean=[0.895, 4.475, 8.950],\n",
    "                    input_draw = draws,\n",
    "                  ):\n",
    "    \n",
    "    data = r.loc[idx[:, duration, cgf_permanent, cgf_permanent, iron_permanent, iron_mean, input_draw],\n",
    "      ['years_of_life_lost', 'years_lived_with_disability', 'person_time']].reset_index()\n",
    "    \n",
    "    fig, ax = plt.subplots(2,2, figsize=(12,8))\n",
    "    \n",
    "    xx = data['coverage']\n",
    "    \n",
    "    measures_short_names = {'years_of_life_lost': 'YLL', 'years_lived_with_disability': 'YLD'}\n",
    "\n",
    "    for i, (measure, short_name) in enumerate(measures_short_names.items()):\n",
    "        ax[i,0].plot(xx, data[measure], '-o')\n",
    "        ax[i,1].plot(xx, 100_000*data[measure] / data['person_time'], '-o', color='orange')\n",
    "    \n",
    "        ax[i,0].set_title(f'Total {short_name} count vs. coverage', fontsize=20)\n",
    "        ax[i,0].set_xlabel('Program Coverage (%)', fontsize=16)\n",
    "        ax[i,0].set_ylabel(f'{short_name}s', fontsize=20)\n",
    "        ax[i,0].grid()\n",
    "#         ax[i,0].legend(loc=(0.8, -.25), fontsize=14)\n",
    "\n",
    "        ax[i,1].set_title(f'Total {short_name} rate vs. coverage', fontsize=20)\n",
    "        ax[i,1].set_xlabel('Program Coverage (%)', fontsize=16)\n",
    "        ax[i,1].set_ylabel(f'{short_name}s per 100,000 person years', fontsize=12)\n",
    "        ax[i,1].grid()\n",
    "        \n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot treated days and estimated fraction of population treated for all draws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.filter(regex='treated_days|population|person_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fraction of population tracked is about 54.4% for all scenarios and draws.\n",
    "# Why? How do you compute this?\n",
    "(r['total_population_tracked']/r['total_population']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_per_year = 365.25\n",
    "years_of_simulation = 5\n",
    "\n",
    "@interact()\n",
    "def plot_treated_days_by_draw(duration=[365.25, 730.50],\n",
    "                    cgf_permanent=[False, True],\n",
    "                    iron_permanent=[False, True],\n",
    "                    iron_mean=[0.895, 4.475, 8.950],\n",
    "                    input_draw = draws,\n",
    "                  ):\n",
    "    \n",
    "    data = r.loc[idx[:, duration, cgf_permanent, cgf_permanent, iron_permanent, iron_mean, input_draw],\n",
    "      ['sqlns_treated_days', 'total_population_living', 'total_population_tracked', 'person_time']].reset_index()\n",
    "    \n",
    "    fig, ax = plt.subplots(1,2, figsize=(13,6))\n",
    "    \n",
    "    xx = data['coverage']\n",
    "    \n",
    "\n",
    "    ax[0].plot(xx, data['sqlns_treated_days'] / days_per_year, '-o')\n",
    "#     # This is computing something like \"average person years per treatment year for a treated simulant\",\n",
    "#     # then multiplying that by the number of treated years over the number of person years.\n",
    "#     ax[1].plot(xx,\n",
    "#                (data['total_population_living'] / data['total_population_tracked']) *\n",
    "#                years_of_simulation * data['sqlns_treated_days'] / (duration * data['person_time']),\n",
    "#                '-o', color='orange')\n",
    "    ax[1].plot(xx, data['sqlns_treated_days'] / (duration * data['total_population_tracked']),\n",
    "               '-o', color='orange')\n",
    "\n",
    "    ax[0].set_title('Treated years vs. coverage', fontsize=20)\n",
    "    ax[0].set_xlabel('Program Coverage (%)', fontsize=16)\n",
    "    ax[0].set_ylabel('SQ-LNS treated years', fontsize=20)\n",
    "    ax[0].grid()\n",
    "#         ax[i,0].legend(loc=(0.8, -.25), fontsize=14)\n",
    "\n",
    "    ax[1].set_title('Estimated fraction of\\npopulation treated vs. coverage', fontsize=20)\n",
    "    ax[1].set_xlabel('Program Coverage (%)', fontsize=16)\n",
    "#     ax[1].set_ylabel('(survival-rate)\\nx (simulation-duration / treatment-duration)\\nx (treated-years / person-years)', fontsize=12)\n",
    "    ax[1].set_ylabel('sqlns_treated_time /\\n(treatment_duration x population_tracked)', fontsize=12)\n",
    "    ax[1].grid()\n",
    "        \n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on the graphs, estimated coverage is close to program coverage -- how close?\n",
    "\n",
    "The maximum difference is less than 2%, with a mean around 0.28%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(100*r.sqlns_treated_days / \n",
    " (r.index.get_level_values('duration') * r.total_population_tracked)\n",
    " - r.index.get_level_values('coverage')).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we invert the equation to estimate treated years from coverage, how close do we get?\n",
    "\n",
    "The maximum difference is about 1764 treated years, with a mean around 208 treated years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((r.sqlns_treated_days\n",
    " - 0.01*r.index.get_level_values('coverage')\n",
    " * r.index.get_level_values('duration')\n",
    " * r.total_population_tracked)/days_per_year).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions to transform data into \"long\" form suitible for more analysis/graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_shape(data, measure):\n",
    "    measure_data = data.loc[:, [c for c in data.columns if measure in c]]\n",
    "    measure_data = measure_data.stack().reset_index().rename(columns={'level_7': 'label', 0: 'value'})\n",
    "    if 'due_to' in measure:\n",
    "        measure, cause = measure.split('_due_to_', 1)\n",
    "        measure_data.loc[:, 'measure'] = measure\n",
    "        measure_data.loc[:, 'cause'] = cause\n",
    "    else:\n",
    "        measure_data.loc[:, 'measure'] = measure  \n",
    "    measure_data.drop(columns='label', inplace=True)\n",
    "    \n",
    "    return measure_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_person_time(data):\n",
    "    pt = standardize_shape(data, 'person_time')\n",
    "    pt = pt.rename(columns={'value': 'person_time'}).drop(columns='measure')\n",
    "    return pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_treated_days(data):\n",
    "    treated = standardize_shape(data, 'sqlns_treated_days')\n",
    "    treated = treated.rename(columns={'value': 'sqlns_treated_days'}).drop(columns='measure')\n",
    "    return treated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_person_time(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_treated_days(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disaggregated_results(data, cause_names):\n",
    "    deaths = []\n",
    "    ylls = []\n",
    "    ylds = []\n",
    "    dalys = []\n",
    "    for cause in cause_names:\n",
    "        if cause in cause_names[:4]:\n",
    "            deaths.append(standardize_shape(data, f'death_due_to_{cause}'))\n",
    "            \n",
    "            ylls_sub = standardize_shape(data, f'ylls_due_to_{cause}')\n",
    "            ylds_sub = standardize_shape(data, f'ylds_due_to_{cause}')\n",
    "            dalys_sub = (ylds_sub.set_index([c for c in template_cols if c != 'measure']) + \\\n",
    "                         ylls_sub.set_index([c for c in template_cols if c != 'measure'])).reset_index()\n",
    "            dalys_sub['measure'] = 'dalys'\n",
    "            \n",
    "            ylls.append(ylls_sub)\n",
    "            ylds.append(ylds_sub)\n",
    "            dalys.append(dalys_sub)\n",
    "        elif cause == 'iron_deficiency':\n",
    "            ylds_sub = standardize_shape(data, f'ylds_due_to_{cause}')     \n",
    "            dalys_sub = ylds_sub.copy()\n",
    "            dalys_sub['measure'] = 'dalys'\n",
    "            \n",
    "            ylds.append(ylds_sub)\n",
    "            dalys.append(dalys_sub)\n",
    "        else: # cause == 'other_causes'\n",
    "            deaths.append(standardize_shape(data, f'death_due_to_{cause}'))\n",
    "            \n",
    "            ylls_sub = standardize_shape(data, f'ylls_due_to_{cause}')\n",
    "            dalys_sub = ylls_sub.copy()\n",
    "            dalys_sub['measure'] = 'dalys'\n",
    "            \n",
    "            ylls.append(ylls_sub)\n",
    "            dalys.append(dalys_sub)\n",
    "    \n",
    "    death_data = pd.concat(deaths, sort=False)\n",
    "    yll_data = pd.concat(ylls, sort=False)\n",
    "    yld_data = pd.concat(ylds, sort=False)\n",
    "    daly_data = pd.concat(dalys, sort=False)\n",
    "    \n",
    "    output = pd.concat([death_data, yll_data, yld_data, daly_data], sort=False)\n",
    "    output = output.set_index(template_cols).sort_index()\n",
    "    \n",
    "    return output.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = get_disaggregated_results(r, cause_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add columns recording person time and treated time for each (scenario, draw, cause) combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_columns = [c for c in template_cols if c not in ['cause', 'measure']]\n",
    "df = output.merge(get_person_time(r), on=join_columns).merge(get_treated_days(r), on=join_columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to plot mortality/DALY/YLL/YLD by disease at the draw level\n",
    "\n",
    "Each raw measure is plotted side by side with its rate per 100,000 person years. Plots should be monotonically decreasing as coverage level increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact()\n",
    "def plot_cause_spceific_dalys_by_draw(duration=[365.25, 730.50],\n",
    "                    cgf_permanent=[False, True],\n",
    "                    iron_permanent=[False, True],\n",
    "                    iron_mean=[0.895, 4.475, 8.950],\n",
    "                    input_draw = df.input_draw.unique(),\n",
    "                    measure = df.measure.unique(),\n",
    "                    include_other_causes=True,\n",
    "                  ):\n",
    "    \n",
    "    data = df.loc[(df.duration == duration)\n",
    "                  & (df.child_stunting_permanent == cgf_permanent)\n",
    "                  & (df.child_wasting_permanent == cgf_permanent)\n",
    "                  & (df.iron_deficiency_permanent == iron_permanent)\n",
    "                  & (df.iron_deficiency_mean == iron_mean)\n",
    "                  & (df.input_draw == input_draw)\n",
    "                  & (df.measure == measure)]\n",
    "    \n",
    "    fig, ax = plt.subplots(1,2, figsize=(18,8))\n",
    "    \n",
    "    # 'other_causes' value is much higher - can omit by indexing with [:-1]\n",
    "    displayed_causes = cause_names if include_other_causes else cause_names[:-1]\n",
    "    for cause in displayed_causes:\n",
    "        data_sub = data.loc[data.cause == cause]\n",
    "        \n",
    "        xx = data_sub['coverage']\n",
    "        value = data_sub['value']\n",
    "        value_over_pt = 100_000* data_sub['value'] / data_sub['person_time']\n",
    "        \n",
    "        ax[0].plot(xx, value, '-o', label=cause)\n",
    "        ax[1].plot(xx, value_over_pt, '-o')\n",
    "        \n",
    "    singular_measure = measure if measure=='death' else measure[:-1]\n",
    "    plural_measure = 'deaths' if measure=='death' else measure\n",
    "    \n",
    "    ax[0].set_title(f'{singular_measure.upper()} count by disease vs. coverage', fontsize=20)\n",
    "    ax[0].set_xlabel('Program Coverage (%)', fontsize=20)\n",
    "    ax[0].set_ylabel(f'{plural_measure.upper()}', fontsize=20)\n",
    "    ax[0].grid()\n",
    "    ax[0].legend(loc=(0.9, -.3))\n",
    "    \n",
    "    ax[1].set_title(f'{singular_measure.upper()} rate by disease vs. coverage', fontsize=20)\n",
    "    ax[1].set_xlabel('Program Coverage (%)', fontsize=20)\n",
    "    ax[1].set_ylabel(f'{plural_measure.upper()} per 100,000 person years', fontsize=20)\n",
    "    ax[1].grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate averted DALYs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_averted_results(df):\n",
    "    bau = df[df.coverage == 0.0].drop(columns=['coverage', 'person_time'])\n",
    "    t = pd.merge(df, bau, on=template_cols[1:], suffixes=['', '_bau'])\n",
    "    t['averted'] = t['value_bau'] - t['value']\n",
    "#     t.drop(columns='value_bau', inplace=True)\n",
    "    \n",
    "    t['value'] = (t['value']/t['person_time']) * 100_000\n",
    "    t['averted'] = (t['averted']/t['person_time']) * 100_000\n",
    "    \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_averted_results(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_table(data):\n",
    "    g = data.groupby(template_cols[:-1])[['person_time', 'value', 'averted']]\\\n",
    "            .describe(percentiles=[.025, .975])\n",
    "    \n",
    "    table = g.filter([('value', 'mean'), ('value', '2.5%'), ('value', '97.5%'),\n",
    "                      ('person_time', 'mean'), ('person_time', '2.5%'), ('person_time', '97.5%'),\n",
    "                      ('averted', 'mean'), ('averted', '2.5%'), ('averted', '97.5%')])\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_shell = get_final_table(get_averted_results(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_shell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original plot of averted DALYs that tipped us off that something was wrong\n",
    "\n",
    "The graph is not monotone with coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact()\n",
    "def plot_dalys_averted(duration=[365.25, 730.50],\n",
    "                       cgf_permanent=[False, True],\n",
    "                       iron_permanent=[False, True],\n",
    "                       iron_mean=[0.895, 4.475, 8.950],\n",
    "                       include_other_causes=False\n",
    "                      ):\n",
    "    \n",
    "    df = table_shell.reset_index()\n",
    "    \n",
    "    data = df.loc[(df.duration == duration)\n",
    "                  & (df.child_stunting_permanent == cgf_permanent)\n",
    "                  & (df.child_wasting_permanent == cgf_permanent)\n",
    "                  & (df.iron_deficiency_permanent == iron_permanent)\n",
    "                  & (df.iron_deficiency_mean == iron_mean)\n",
    "                  & (df.measure == 'dalys')]\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # 'other_causes' value is much higher - can omit by indexing with [:-1]\n",
    "    displayed_causes = cause_names if include_other_causes else cause_names[:-1]\n",
    "    for cause in displayed_causes:\n",
    "        data_sub = data.loc[data.cause == cause]\n",
    "        \n",
    "        xx = data_sub['coverage']\n",
    "        mean = data_sub[('averted', 'mean')]\n",
    "        lb = data_sub[('averted', '2.5%')]\n",
    "        ub = data_sub[('averted', '97.5%')]\n",
    "        \n",
    "        plt.plot(xx, mean, '-o', label=cause)\n",
    "        plt.fill_between(xx, lb, ub, alpha=0.1)\n",
    "    \n",
    "    plt.title('Nigeria')\n",
    "    plt.xlabel('Program Coverage (%)')\n",
    "    plt.ylabel('DALYs Averted (per100,000PY)')\n",
    "    plt.legend(loc=(1.05, .05))\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check averted DALYs data to find the problem\n",
    "\n",
    "The problem with the averted DALYs graphs is that DALYs are being subtracted **before** dividing by person time, whereas the subtraction should actually happen **after** dividing by the person time for the specific scenario:\n",
    "```python\n",
    "def get_averted_results(df):\n",
    "    bau = df[df.coverage == 0.0].drop(columns=['coverage', 'person_time'])\n",
    "    t = pd.merge(df, bau, on=template_cols[1:], suffixes=['', '_bau'])\n",
    "    # NOTE: This computes the difference in DALY count, not DALY rate:\n",
    "    t['averted'] = t['value_bau'] - t['value']\n",
    "#     t.drop(columns='value_bau', inplace=True)\n",
    "    \n",
    "    t['value'] = (t['value']/t['person_time']) * 100_000\n",
    "    # NOTE: This calculation ignores person time for 0% coverage, dividing\n",
    "    #  the difference in DALYs by the person time for the intervention:\n",
    "    t['averted'] = (t['averted']/t['person_time']) * 100_000\n",
    "    \n",
    "    return t\n",
    "```\n",
    "\n",
    "Dividing by person time first would ensure that we're subtracting quantities that are on comparable scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averted_df = get_averted_results(df)\n",
    "averted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r.loc[idx[:, 365.25, False, False, False, 0.895, 357],\n",
    "#       ['death_due_to_other_causes', 'death_due_to_diarrheal_diseases', 'ylds_due_to_iron_deficiency']]\n",
    "sub_df = averted_df.loc[(averted_df.duration==365.25)\n",
    "               & (averted_df.child_stunting_permanent==False)\n",
    "               & (averted_df.child_wasting_permanent==False)\n",
    "               & (averted_df.iron_deficiency_permanent==False)\n",
    "               & (averted_df.iron_deficiency_mean==0.895)\n",
    "               & (averted_df.input_draw==357)\n",
    "               & (averted_df.cause=='diarrheal_diseases')\n",
    "               & (averted_df.measure=='dalys')\n",
    "               ,['coverage', 'person_time', 'value', 'value_bau', 'averted']\n",
    "              ]\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should be 0, based on calculation in `get_averted_results()`.\n",
    "sub_df['value_bau'] - (sub_df['value']+sub_df['averted'])*sub_df['person_time']/100_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This computes the original DALY values for each coverage level.\n",
    "# We can verify the numbers against the above graph of DALYs by disease for draw 357.\n",
    "sub_df['value']*sub_df['person_time']/100_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This computes the original difference in DALYs between X% coverage and 0% coverage.\n",
    "# Note the very large value at 40%, matching the above graphs.\n",
    "sub_df['averted']*sub_df['person_time']/100_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw a graph of aggregated DALYs per 100,000 PY, rather than averted DALYs\n",
    "\n",
    "The actual averted DALYs per $10^5$ PY would be the difference in y values of this graph from 0% to the various coverage levels. However, to draw the new graph for averted DALYs, we need to rewrite the `get_averted_dalys()` function and re-aggregate the data; see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact()\n",
    "def plot_dalys_per_1e5_py(duration=[365.25, 730.50],\n",
    "                       cgf_permanent=[False, True],\n",
    "                       iron_permanent=[False, True],\n",
    "                       iron_mean=[0.895, 4.475, 8.950],\n",
    "                        include_other_causes=False):\n",
    "    \n",
    "    df = table_shell.reset_index()\n",
    "    \n",
    "    data = df.loc[(df.duration == duration)\n",
    "                  & (df.child_stunting_permanent == cgf_permanent)\n",
    "                  & (df.child_wasting_permanent == cgf_permanent)\n",
    "                  & (df.iron_deficiency_permanent == iron_permanent)\n",
    "                  & (df.iron_deficiency_mean == iron_mean)\n",
    "                  & (df.measure == 'dalys')]\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # 'other_causes' value is much higher - can omit by indexing with [:-1]\n",
    "    displayed_causes = cause_names if include_other_causes else cause_names[:-1]\n",
    "    for cause in displayed_causes:\n",
    "        data_sub = data.loc[data.cause == cause]\n",
    "        \n",
    "        xx = data_sub['coverage']\n",
    "        mean_per_py = data_sub[('value', 'mean')]\n",
    "        lb = data_sub[('value', '2.5%')]\n",
    "        ub = data_sub[('value', '97.5%')]\n",
    "        \n",
    "        plt.plot(xx, mean_per_py, '-o', label=cause)\n",
    "        plt.fill_between(xx, lb, ub, alpha=0.1)\n",
    "    \n",
    "    plt.title('Nigeria')\n",
    "    plt.xlabel('Program Coverage (%)')\n",
    "    plt.ylabel('DALYs per 100,000 PY')\n",
    "    plt.legend(loc=(1.05, .05))\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rewrite averted DALYs function to compute in rate space, and draw new graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_averted_results_in_rate_space(df):\n",
    "    bau = df[df.coverage == 0.0].drop(columns=['coverage'])\n",
    "    t = pd.merge(df, bau, on=template_cols[1:], suffixes=['', '_bau'])\n",
    "    t['averted'] = (t['value_bau']/t['person_time_bau'] - t['value']/t['person_time']) * 100_000\n",
    "    \n",
    "#     t['value'] = (t['value']/t['person_time']) * 100_000\n",
    "#     t['averted'] = (t['averted']/t['person_time']) * 100_000\n",
    "    \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averted_rate_space_df = get_averted_results_in_rate_space(df)\n",
    "averted_rate_space_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_results_df = get_final_table(averted_rate_space_df)\n",
    "aggregated_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_results_df = aggregated_results_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact()\n",
    "def plot_dalys_averted_rate_space(duration=[365.25, 730.50],\n",
    "                       cgf_permanent=[False, True],\n",
    "                       iron_permanent=[False, True],\n",
    "                       iron_mean=[0.895, 4.475, 8.950],\n",
    "                       measure = aggregated_results_df.measure.unique(),\n",
    "                       include_other_causes=False,\n",
    "                      ):\n",
    "    \n",
    "    df = aggregated_results_df\n",
    "    \n",
    "    data = df.loc[(df.duration == duration)\n",
    "                  & (df.child_stunting_permanent == cgf_permanent)\n",
    "                  & (df.child_wasting_permanent == cgf_permanent)\n",
    "                  & (df.iron_deficiency_permanent == iron_permanent)\n",
    "                  & (df.iron_deficiency_mean == iron_mean)\n",
    "                  & (df.measure == measure)]\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # 'other_causes' value is much higher - can omit by indexing with [:-1]\n",
    "    displayed_causes = cause_names if include_other_causes else cause_names[:-1]\n",
    "    for cause in displayed_causes:\n",
    "        data_sub = data.loc[data.cause == cause]\n",
    "        \n",
    "        xx = data_sub['coverage']\n",
    "        mean = data_sub[('averted', 'mean')]\n",
    "        lb = data_sub[('averted', '2.5%')]\n",
    "        ub = data_sub[('averted', '97.5%')]\n",
    "        \n",
    "        plt.plot(xx, mean, '-o', label=cause)\n",
    "        plt.fill_between(xx, lb, ub, alpha=0.1)\n",
    "    \n",
    "    plt.title('Nigeria')\n",
    "    plt.xlabel('Program Coverage (%)')\n",
    "    plt.ylabel(f'{measure.upper()} Averted (per 100,000 PY)')\n",
    "    plt.legend(loc=(1.05, .05))\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
